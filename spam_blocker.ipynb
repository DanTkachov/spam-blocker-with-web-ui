{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.074969Z",
     "start_time": "2024-05-31T17:43:13.515648Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.077548Z",
     "start_time": "2024-05-31T17:43:14.075829Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"Hello World\")",
   "id": "8ea09a2d0189d47e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.095737Z",
     "start_time": "2024-05-31T17:43:14.078033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read in the input data\n",
    "# Data gathered from this link: https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset/data\n",
    "\n",
    "df = pd.read_csv('data/spam.csv', encoding='latin1')\n",
    "df.head()"
   ],
   "id": "18b9c8809379c9c7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.099434Z",
     "start_time": "2024-05-31T17:43:14.096478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get rid of columns without any data in them\n",
    "bad_columns = ['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
    "df.drop(bad_columns, axis=1, inplace=True)\n",
    "df.columns = ['Category', 'Message']\n",
    "\n",
    "# Check for missing values\n",
    "df.isna().sum()"
   ],
   "id": "164138994fb40b7e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category    0\n",
       "Message     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.108939Z",
     "start_time": "2024-05-31T17:43:14.099864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Drop duplicated rows\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df.duplicated().sum()"
   ],
   "id": "e665a88068e97cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.115396Z",
     "start_time": "2024-05-31T17:43:14.109390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get the number of each category\n",
    "num_spam = df[df['Category'] == 'spam'].shape[0]\n",
    "num_non_spam = df[df['Category'] == 'ham'].shape[0]\n",
    "print(\"Spam emails: \", num_spam, f\" Percent of total: {100 * num_spam / (num_spam + num_non_spam):.1f}%\")\n",
    "print(\"Non-spam emails: \", num_non_spam, f\" Percent of total: {100 * num_non_spam / (num_spam + num_non_spam):.1f}%\")"
   ],
   "id": "b02c53c74955293d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam emails:  653  Percent of total: 12.6%\n",
      "Non-spam emails:  4516  Percent of total: 87.4%\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.125119Z",
     "start_time": "2024-05-31T17:43:14.115898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert the category column to a column of 1's denoting spam, 0's denoting not spam.\n",
    "\n",
    "mapping = {'ham': 0, 'spam': 1}\n",
    "df['spam'] = df['Category'].map(mapping)\n",
    "df = df.drop('Category', axis=1)\n",
    "df.head()"
   ],
   "id": "e0793ab13af52073",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             Message  spam\n",
       "0  Go until jurong point, crazy.. Available only ...     0\n",
       "1                      Ok lar... Joking wif u oni...     0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...     1\n",
       "3  U dun say so early hor... U c already then say...     0\n",
       "4  Nah I don't think he goes to usf, he lives aro...     0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.139168Z",
     "start_time": "2024-05-31T17:43:14.125678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into a training set and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['Message'], df['spam'], test_size=0.2)"
   ],
   "id": "3b08de276e2975c3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:43:14.228064Z",
     "start_time": "2024-05-31T17:43:14.139652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature extraction\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf = vectorizer.transform(x_test)\n",
    "\n",
    "x_train_dense = x_train_tfidf.toarray()\n",
    "x_test_dense = x_test_tfidf.toarray()"
   ],
   "id": "e8744d8db3510924",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:51:52.346951Z",
     "start_time": "2024-05-31T17:50:17.747951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build the model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Using a simpler, statically trained model is fine here. The classification does not have any internal state so using more complex architectures like RNN's is not necessary.\n",
    "\n",
    "model = keras.Sequential()\n",
    "# model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.03, l2=0.00)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_dense, y_train, epochs=20, batch_size=1, validation_split=0.2)"
   ],
   "id": "16159c10fa47b67d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.8892 - loss: 0.3163 - val_accuracy: 0.9879 - val_loss: 0.0608\n",
      "Epoch 2/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9830 - loss: 0.0647 - val_accuracy: 0.9867 - val_loss: 0.0412\n",
      "Epoch 3/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9937 - loss: 0.0208 - val_accuracy: 0.9867 - val_loss: 0.0406\n",
      "Epoch 4/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9947 - loss: 0.0142 - val_accuracy: 0.9867 - val_loss: 0.0454\n",
      "Epoch 5/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9960 - loss: 0.0091 - val_accuracy: 0.9879 - val_loss: 0.0498\n",
      "Epoch 6/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9973 - loss: 0.0063 - val_accuracy: 0.9855 - val_loss: 0.0590\n",
      "Epoch 7/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9983 - loss: 0.0038 - val_accuracy: 0.9879 - val_loss: 0.0576\n",
      "Epoch 8/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9991 - loss: 0.0023 - val_accuracy: 0.9879 - val_loss: 0.0637\n",
      "Epoch 9/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9879 - val_loss: 0.0676\n",
      "Epoch 10/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 0.9997 - loss: 0.0013 - val_accuracy: 0.9867 - val_loss: 0.0806\n",
      "Epoch 11/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 4.8215e-04 - val_accuracy: 0.9867 - val_loss: 0.0709\n",
      "Epoch 12/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 2.0781e-04 - val_accuracy: 0.9867 - val_loss: 0.0784\n",
      "Epoch 13/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 2.5217e-04 - val_accuracy: 0.9879 - val_loss: 0.0842\n",
      "Epoch 14/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 1.4187e-04 - val_accuracy: 0.9867 - val_loss: 0.0963\n",
      "Epoch 15/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 1.3133e-04 - val_accuracy: 0.9867 - val_loss: 0.0998\n",
      "Epoch 16/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 2.7663e-05 - val_accuracy: 0.9867 - val_loss: 0.1093\n",
      "Epoch 17/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 1.2217e-04 - val_accuracy: 0.9879 - val_loss: 0.1012\n",
      "Epoch 18/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 7.5853e-06 - val_accuracy: 0.9867 - val_loss: 0.1117\n",
      "Epoch 19/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 1.7411e-05 - val_accuracy: 0.9879 - val_loss: 0.1090\n",
      "Epoch 20/20\n",
      "\u001B[1m3308/3308\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 1ms/step - accuracy: 1.0000 - loss: 6.2029e-06 - val_accuracy: 0.9867 - val_loss: 0.1306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x791868323dd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:52:32.836978Z",
     "start_time": "2024-05-31T17:52:32.752776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_probability = model.predict(x_test_dense)\n",
    "y_pred = (y_pred_probability > 0.3).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)"
   ],
   "id": "4bb763106c562b5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m33/33\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 803us/step\n",
      "Accuracy: 0.9835589941972921\n",
      "Precision: 0.968\n",
      "Recall: 0.9029850746268657\n",
      "F1-score: 0.9343629343629344\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T00:35:45.344236Z",
     "start_time": "2024-06-01T00:35:45.272696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def classify_email(email_text):\n",
    "    email_tfidf = vectorizer.transform([email_text])\n",
    "    print(\"Transformed email shape:\", email_tfidf.shape)\n",
    "    prediction = model.predict(email_tfidf)[0]\n",
    "    print(prediction)\n",
    "    return \"Spam\" if prediction >= 0.4 else \"Not Spam\"\n",
    "\n",
    "# Example usage\n",
    "new_email = \"yur sfh sdthshfgsf ddf\"\n",
    "result = classify_email(new_email)\n",
    "print(\"Email classification:\", result)\n",
    "model.summary()"
   ],
   "id": "6efdcd90c1e9633c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed email shape: (1, 7611)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 20:35:45.328192: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at ragged_gather_op.cc:77 : INVALID_ARGUMENT: indices[0] = 0 is not in [0, 0)\n",
      "2024-05-31 20:35:45.328212: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at ragged_gather_op.cc:77 : INVALID_ARGUMENT: indices[0] = 0 is not in [0, 0)\n",
      "2024-05-31 20:35:45.328255: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: indices[0] = 0 is not in [0, 0)\n",
      "\t [[{{node RaggedGather_1/RaggedGather}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 0 is not in [0, 0)\n\t [[{{node RaggedGather_1/RaggedGather}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[32], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Example usage\u001B[39;00m\n\u001B[1;32m      9\u001B[0m new_email \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myur sfh sdthshfgsf ddf\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 10\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mclassify_email\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_email\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmail classification:\u001B[39m\u001B[38;5;124m\"\u001B[39m, result)\n\u001B[1;32m     12\u001B[0m model\u001B[38;5;241m.\u001B[39msummary()\n",
      "Cell \u001B[0;32mIn[32], line 4\u001B[0m, in \u001B[0;36mclassify_email\u001B[0;34m(email_text)\u001B[0m\n\u001B[1;32m      2\u001B[0m email_tfidf \u001B[38;5;241m=\u001B[39m vectorizer\u001B[38;5;241m.\u001B[39mtransform([email_text])\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTransformed email shape:\u001B[39m\u001B[38;5;124m\"\u001B[39m, email_tfidf\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m----> 4\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43memail_tfidf\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(prediction)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSpam\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m prediction \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.4\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNot Spam\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/spam-blocker/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/PycharmProjects/spam-blocker/.venv/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:5983\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   5981\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m NoReturn:\n\u001B[1;32m   5982\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m-> 5983\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} indices[0] = 0 is not in [0, 0)\n\t [[{{node RaggedGather_1/RaggedGather}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T17:54:22.604976Z",
     "start_time": "2024-05-31T17:54:22.582741Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # Save the model using the pickle library\n",
    "import pickle\n",
    "\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ],
   "id": "9e9dfcfc78ed731c",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T00:09:29.013608Z",
     "start_time": "2024-06-01T00:09:29.010749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)"
   ],
   "id": "fa41fa7e05b100ce",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bd31eed7bc23d7ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
